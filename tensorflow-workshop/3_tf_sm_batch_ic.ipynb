{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making batch predictions using a TensorFlow model with Amazon SageMaker\n",
    "This notebook shows how to make **batch predictions with TensorFlow on SageMaker**. Many customers have machine learning workloads that require a large number of predictions to be made reliably on a repeatable schedule. As compared to SageMaker's managed hosting service, inference compute capacity for batch predictions is spun up on demand and taken down upon completion of the batch. For large batch workloads, this represents significant cost savings over an always-on endpoint. Data scientists can stay focused on creating the best models, since [SageMaker batch](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) uses the same trained model easily across hosted endpoints and batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import tensorflow\n",
    "from sagemaker.tensorflow.serving import Model\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help with evaluating the batch prediction results, enter the list of class labels that your classifier was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name_list = ['013.Bobolink', '017.Cardinal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assumes you have already trained your TensorFlow model, which results in model artifacts being available in S3. Update the `training_job_name` variable to refer to your specific training job so that the notebook has a full s3 URI to the model artifacts. These same model artifacts were used for deployment in a SageMaker hosted endpoint in the previous lab. In this lab, we demonstrate batch predictions with the same trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-355151823911/mpr-tf-ic-2019-09-08-04-24-51-045/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'DEMO-TF-image-classification-birds'\n",
    "training_job_name = 'mpr-tf-ic-2019-09-08-04-24-51-045'\n",
    "\n",
    "model_artifacts = 's3://{}/{}/output/model.tar.gz'.format(bucket, training_job_name)\n",
    "print(model_artifacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we instantiate a Model object pointing to the trained model artifacts and referring to the TensorFlow Serving image that will be used to drive inference on that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelArn': 'arn:aws:sagemaker:us-east-1:355151823911:model/mpr-tf-ic-gpu-08-04-36-18',\n",
       " 'ResponseMetadata': {'RequestId': '9c4dbcd5-42e3-4487-a379-3cb96e836203',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '9c4dbcd5-42e3-4487-a379-3cb96e836203',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '87',\n",
       "   'date': 'Sun, 08 Sep 2019 04:36:17 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = boto3.client('sagemaker')\n",
    "\n",
    "model_name = 'mpr-tf-ic-gpu-{}'.format(strftime(\"%d-%H-%M-%S\", gmtime()))\n",
    "\n",
    "tf_serving_model = Model(model_data=model_artifacts,\n",
    "                         role=sagemaker.get_execution_role(),\n",
    "                         image='520713654638.dkr.ecr.us-east-1.amazonaws.com/sagemaker-tensorflow-serving:1.12-gpu',\n",
    "                         framework_version='1.12', # 1.13.1-gpu not found; 1.12 works even if model trained in 1.13.1\n",
    "                         sagemaker_session=sess)\n",
    "\n",
    "batch_instance_type = 'ml.p3.2xlarge'\n",
    "tf_serving_container = tf_serving_model.prepare_container_def(batch_instance_type)\n",
    "model_params = {\n",
    "    'ModelName': model_name,\n",
    "    'Containers': [\n",
    "        tf_serving_container\n",
    "    ],\n",
    "    'ExecutionRoleArn': sagemaker.get_execution_role()\n",
    "}\n",
    "\n",
    "client.create_model(**model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker batch transformations require input to be specified in s3, and you need to provide an s3 output path where SageMaker will save the resulting predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-355151823911/DEMO-TF-image-classification-birds/batch-predictions\n"
     ]
    }
   ],
   "source": [
    "input_data_path = 's3://sagemaker-us-east-1-355151823911/DEMO-TF-image-classification-birds/train/'\n",
    "output_data_path = 's3://{}/{}/{}'.format(bucket, prefix, 'batch-predictions')\n",
    "print(output_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run the batch transformation, we first remove prior batch prediction results. In production, you would likely instead tag the folder with a timestamp and retain the results from each run of the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you sure you want to remove the old batch predictions?no\n"
     ]
    }
   ],
   "source": [
    "if input('Are you sure you want to remove the old batch predictions?') == 'yes':\n",
    "    !aws s3 rm --quiet --recursive $output_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, to interpret the results, we copy them down to our local folder. If we have done this before, we first remove the old results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you sure you want to remove the prior local batch predictions from ./batch_predictionsno\n"
     ]
    }
   ],
   "source": [
    "if input('Are you sure you want to remove the prior local batch predictions from ./batch_predictions') == 'yes':\n",
    "    !rm -rf ./batch_predictions/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we kick off the batch prediction job using the SageMaker Transformer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................!\n"
     ]
    }
   ],
   "source": [
    "batch_instance_count = 2\n",
    "concurrency = 100\n",
    "\n",
    "transformer = sagemaker.transformer.Transformer(\n",
    "    model_name = model_name,\n",
    "    instance_count = batch_instance_count,\n",
    "    instance_type = batch_instance_type,\n",
    "    max_concurrent_transforms = concurrency,\n",
    "    output_path = output_data_path,\n",
    "    base_transform_job_name='tf-birds-image-transform')\n",
    "\n",
    "transformer.transform(data = input_data_path, content_type = 'application/x-image')\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate evaluation of the output, we download the results to our local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --quiet --recursive $output_data_path ./batch_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "predicted = []\n",
    "actual = []\n",
    "\n",
    "for entry in glob.glob('batch_predictions/*/*'):\n",
    "    try:\n",
    "        actual_label = entry.split('/')[1]\n",
    "        actual_index = class_name_list.index(actual_label)\n",
    "        with open(entry, 'r') as f:\n",
    "            jstr = json.load(f)\n",
    "            results = [float('%.3f'%(item)) for sublist in jstr['predictions'] for item in sublist]\n",
    "            class_index = np.argmax(np.array(results))\n",
    "            predicted_label = class_name_list[class_index]\n",
    "            predicted.append(class_index)\n",
    "            actual.append(actual_index)\n",
    "            is_correct = (predicted_label == actual_label) or False\n",
    "            if is_correct:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 70 total images, accurate predictions were returned for 70\n",
      "Accuracy is 100.0%\n"
     ]
    }
   ],
   "source": [
    "print('Out of {} total images, accurate predictions were returned for {}'.format(total, correct))\n",
    "accuracy = correct / total\n",
    "print('Accuracy is {:.1%}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
