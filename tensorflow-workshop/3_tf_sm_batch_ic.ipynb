{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making batch predictions using a TensorFlow model with Amazon SageMaker\n",
    "This notebook shows how to make **batch predictions with TensorFlow on SageMaker**. Many customers have machine learning workloads that require a large number of predictions to be made reliably on a repeatable schedule. As compared to SageMaker's managed hosting service, compute capacity for batch predictions is spun up on demand and taken down upon completion of the batch. For large batch workloads, this represents significant cost savings over an always-on endpoint. \n",
    "\n",
    "Another benefit of SageMaker batch is that it allows data scientists can stay focused on creating the best models.\n",
    "[SageMaker batch](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) uses the same trained model easily across hosted endpoints and batch, with no need for expensive rewrites or infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import tensorflow\n",
    "from sagemaker.tensorflow.serving import Model\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help with evaluating the batch prediction results, enter the list of class labels that your classifier was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name_list = ['013.Bobolink', '017.Cardinal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assumes you have already trained your TensorFlow model in the prior lab, which results in model artifacts being available in S3. Update the `training_job_name` variable below to refer to your specific training job, so that the notebook has a full s3 URI to the model artifacts. \n",
    "\n",
    "These same model artifacts were used for deployment in a SageMaker hosted endpoint in the previous lab. In this lab, we demonstrate batch predictions with the same trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = 'mpr-tf-ic-2019-09-08-04-24-51-045'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'DEMO-TF-image-classification-birds'\n",
    "model_prefix = 'mpr-tf-ic-gpu'\n",
    "\n",
    "model_artifacts = 's3://{}/{}/output/model.tar.gz'.format(bucket, training_job_name)\n",
    "print(model_artifacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we instantiate a Model object pointing to the trained model artifacts and referring to the TensorFlow Serving image that will be used to drive inference on that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('sagemaker')\n",
    "\n",
    "model_name = '{}-{}'.format(model_prefix, strftime(\"%d-%H-%M-%S\", gmtime()))\n",
    "\n",
    "tf_serving_model = Model(model_data=model_artifacts,\n",
    "                         role=sagemaker.get_execution_role(),\n",
    "                         image='520713654638.dkr.ecr.us-east-1.amazonaws.com/sagemaker-tensorflow-serving:1.12-gpu',\n",
    "                         framework_version='1.12', # 1.13.1-gpu not found; 1.12 works even if model trained in 1.13.1\n",
    "                         sagemaker_session=sess)\n",
    "\n",
    "batch_instance_type = 'ml.p3.2xlarge'\n",
    "tf_serving_container = tf_serving_model.prepare_container_def(batch_instance_type)\n",
    "model_params = {\n",
    "    'ModelName': model_name,\n",
    "    'Containers': [\n",
    "        tf_serving_container\n",
    "    ],\n",
    "    'ExecutionRoleArn': sagemaker.get_execution_role()\n",
    "}\n",
    "\n",
    "client.create_model(**model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker batch transformations require input to be specified in s3, and you need to provide an s3 output path where SageMaker will save the resulting predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_path = 's3://sagemaker-us-east-1-355151823911/DEMO-TF-image-classification-birds/train/'\n",
    "output_data_path = 's3://{}/{}/{}'.format(bucket, prefix, 'batch-predictions')\n",
    "print(output_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run the batch transformation, we first remove prior batch prediction results. In production, you would likely instead tag the folder with a timestamp and retain the results from each run of the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input('Are you sure you want to remove the old batch predictions {}?'.format(output_data_path)) == 'yes':\n",
    "    !aws s3 rm --quiet --recursive $output_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, to interpret the results, we copy them down to our local folder. If we have done this before, we first remove the old results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input('Are you sure you want to remove the prior local batch predictions from ./batch_predictions') == 'yes':\n",
    "    !rm -rf ./batch_predictions/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we kick off the batch prediction job using the SageMaker Transformer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_instance_count = 2\n",
    "concurrency = 100\n",
    "\n",
    "transformer = sagemaker.transformer.Transformer(\n",
    "    model_name = model_name,\n",
    "    instance_count = batch_instance_count,\n",
    "    instance_type = batch_instance_type,\n",
    "    max_concurrent_transforms = concurrency,\n",
    "    output_path = output_data_path,\n",
    "    base_transform_job_name='tf-birds-image-transform')\n",
    "\n",
    "transformer.transform(data = input_data_path, content_type = 'application/x-image')\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate evaluation of the output, we download the results to our local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp  --quiet --recursive $output_data_path ./batch_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we take a look at a sample output file. For each jpg file we passed to the batch transformation job, we get a corresponding `.jpg.out` file containing the json formatted output from the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "filepaths = glob.glob('./batch_predictions/*/*')\n",
    "sample_file = filepaths[0]\n",
    "!cat $sample_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we take the highest probability class prediction for each image and compare that to the actual class of the image (represented by its class subfolder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "predicted = []\n",
    "actual = []\n",
    "\n",
    "for entry in glob.glob('batch_predictions/*/*'):\n",
    "    try:\n",
    "        actual_label = entry.split('/')[1]\n",
    "        actual_index = class_name_list.index(actual_label)\n",
    "        with open(entry, 'r') as f:\n",
    "            jstr = json.load(f)\n",
    "            results = [float('%.3f'%(item)) for sublist in jstr['predictions'] for item in sublist]\n",
    "            class_index = np.argmax(np.array(results))\n",
    "            predicted_label = class_name_list[class_index]\n",
    "            predicted.append(class_index)\n",
    "            actual.append(actual_index)\n",
    "            is_correct = (predicted_label == actual_label) or False\n",
    "            if is_correct:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Out of {} total images, accurate predictions were returned for {}'.format(total, correct))\n",
    "accuracy = correct / total\n",
    "print('Accuracy is {:.1%}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.GnBu):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), \n",
    "                                  range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.gca().set_xticklabels(class_name_list)\n",
    "    plt.gca().set_yticklabels(class_name_list)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def create_and_plot_confusion_matrix(actual, predicted):\n",
    "    cnf_matrix = confusion_matrix(actual, np.asarray(predicted),labels=range(len(class_name_list)))\n",
    "    plot_confusion_matrix(cnf_matrix, classes=range(len(class_name_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_plot_confusion_matrix(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
