{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making batch predictions using a PyTorch model with Amazon SageMaker\n",
    "This notebook shows how to make **batch predictions with PyTorch on SageMaker**. Many customers have machine learning workloads that require a large number of predictions to be made reliably on a repeatable schedule. As compared to SageMaker's managed hosting service, compute capacity for batch predictions is spun up on demand and taken down upon completion of the batch. For large batch workloads, this represents significant cost savings over an always-on endpoint. \n",
    "\n",
    "Another benefit of SageMaker batch is that it allows data scientists can stay focused on creating the best models.\n",
    "[SageMaker batch](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) uses the same trained model easily across hosted endpoints and batch, with no need for expensive rewrites or infrastructure. You provide the input via s3, and SageMaker returns the predictions via s3 as well. Note that the same input and output handlers you used for your SageMaker endpoint in the [previous lab](./2_sm_image_classification_birds.ipynb) are used for batch predictions as well. Likewise, the same trained model works for both. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "This notebook assumes you have already trained your model in the prior lab, which results in model artifacts being available in S3. Update the `training_job_name` variable below to refer to your specific training job, so that the notebook has a full s3 URI to the model artifacts. \n",
    "\n",
    "These same model artifacts were used for deployment in a SageMaker hosted endpoint in the previous lab. In this lab, we demonstrate batch predictions with the same trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "\n",
    "training_job_name = 'pyt-ic-2020-02-19-02-39-01-936'  ### Replace this with your job name from the previous lab\n",
    "\n",
    "USE_GPU_INSTANCE  = True\n",
    "FRAMEWORK_VERSION = '1.3.1'\n",
    "ACCOUNT_NUM = '763104351884' # for most regions\n",
    "CONTAINER_NAME = 'pytorch-inference'\n",
    "print(f'Using account: {ACCOUNT_NUM}, container: {CONTAINER_NAME}')\n",
    "## Here is the documentation for identifying TensorFlow SageMaker container images\n",
    "##   https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "s3_prefix = 'DEMO-PYT-image-classification-birds'\n",
    "region_name = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help with evaluating the batch prediction results, enter the list of class labels that your classifier was trained on in notebook 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name_list = ['013.Bobolink', '017.Cardinal', '035.Purple_Finch', '036.Northern_Flicker']\n",
    "#,\n",
    "#                   '047.American_Goldfinch', '068.Ruby_throated_Hummingbird', '073.Blue_Jay', \n",
    "#                   '075.Green_Jay', '087.Mallard', '095.Baltimore_Oriole', \n",
    "#                   '120.Fox_Sparrow', '179.Tennessee_Warbler', '192.Downy_Woodpecker']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker batch transformations require input to be specified in s3, and you need to provide an s3 output path where SageMaker will save the resulting predictions. For this sample batch job, we will make a prediction for each of the images from our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_path  = f's3://{bucket}/{s3_prefix}/train/'\n",
    "output_data_path = f's3://{bucket}/{s3_prefix}/batch_predictions/'\n",
    "\n",
    "print(f'Batch input from: {input_data_path}')\n",
    "print(f'Batch output to:  {output_data_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run the batch transformation, we first remove prior batch prediction results. In production, you would likely instead tag the folder with a timestamp and retain the results from each run of the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $input_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input('Are you sure you want to remove the old batch predictions {}?'.format(output_data_path)) == 'yes':\n",
    "    !aws s3 rm --quiet --recursive $output_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, to interpret the results, we copy them down to our local folder. If we have done this before, we first remove the old results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input('Are you sure you want to remove the prior local batch predictions from ./batch_predictions') == 'yes':\n",
    "    !rm -rf ./batch_predictions/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Model for performing batch predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we deployed the model in the previous lab to an Amazon SageMaker real time endpoint, we deployed to a CPU-based instance type.  Under the hood a CPU-based Amazon SageMaker Model object was created to wrap a CPU-based TFS container.  However, for Batch Transform on a large dataset, we would prefer to use full GPU instances.  To do this, we need to create another Model object that will utilize a GPU-based TFS container.  \n",
    "\n",
    "First we give a unique name for the model and identify the proper TensorFlow framework image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_GPU_INSTANCE:\n",
    "    device = 'gpu'\n",
    "    batch_instance_type = 'ml.p3.8xlarge'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    batch_instance_type = 'ml.c5.4xlarge'\n",
    "\n",
    "model_artifacts = f's3://{bucket}/{training_job_name}/output/model.tar.gz'\n",
    "model_prefix = f'pyt-ic-{device}'\n",
    "model_name = '{}-{}'.format(model_prefix, strftime(\"%m-%d-%H-%M-%S\", gmtime()))\n",
    "framework_image = \\\n",
    "      f'{ACCOUNT_NUM}.dkr.ecr.{region_name}.amazonaws.com/{CONTAINER_NAME}:{FRAMEWORK_VERSION}-{device}-py3'\n",
    "\n",
    "print(f'Model will be named: {model_name}')\n",
    "print('Using image: {}'.format(framework_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we instantiate a Model object pointing to the trained model artifacts and referring to the TensorFlow Serving image that will be used to drive inference on that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_BOTO3 = True\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "print(f'Creating model for {model_artifacts}')\n",
    "serving_model = PyTorchModel(model_data=model_artifacts,\n",
    "                             entry_point='train-resnet.py',\n",
    "                             source_dir='code',\n",
    "                             role=sagemaker.get_execution_role(),\n",
    "                             image=framework_image,\n",
    "                             framework_version=FRAMEWORK_VERSION,\n",
    "                             sagemaker_session=sess)\n",
    "if USE_BOTO3:\n",
    "    client = boto3.client('sagemaker')\n",
    "    tf_serving_container = serving_model.prepare_container_def(batch_instance_type)\n",
    "    model_params = {\n",
    "        'ModelName': model_name,\n",
    "        'Containers': [\n",
    "            tf_serving_container\n",
    "        ],\n",
    "        'ExecutionRoleArn': sagemaker.get_execution_role()\n",
    "    }\n",
    "    client.create_model(**model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch the batch transformation job\n",
    "Here we kick off the batch prediction job using the SageMaker Transformer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "batch_instance_count = 2\n",
    "concurrency = 64\n",
    "\n",
    "if USE_BOTO3:\n",
    "    transformer = sagemaker.transformer.Transformer(\n",
    "        model_name=model_name,\n",
    "        instance_count = batch_instance_count,\n",
    "        instance_type  = batch_instance_type,\n",
    "        max_concurrent_transforms = concurrency,\n",
    "        output_path    = output_data_path,\n",
    "        base_transform_job_name='pyt-birds-image-transform')\n",
    "else:\n",
    "    transformer = serving_model.transformer(\n",
    "        instance_count = batch_instance_count,\n",
    "        instance_type  = batch_instance_type,\n",
    "        max_concurrent_transforms = concurrency,\n",
    "        output_path    = output_data_path)\n",
    "\n",
    "transformer.transform(data = input_data_path, content_type = 'application/x-image')\n",
    "#transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate prediction results\n",
    "To facilitate evaluation of the output, we download the results to our local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp  --quiet --recursive $output_data_path ./batch_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we take a look at a sample output file. For each jpg file we passed to the batch transformation job, we get a corresponding `.jpg.out` file containing the json formatted output from the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "filepaths = glob.glob('./batch_predictions/*/*')\n",
    "print('Total number of predictions: {}'.format(len(filepaths)))\n",
    "print('\\nSample prediction output file:')\n",
    "sample_file = filepaths[0]\n",
    "!cat $sample_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the larger scale batch predictions on images we don't yet have labelled, we'll simply parse the prediction output files to see the distribution of predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "predicted = []\n",
    "\n",
    "for entry in glob.glob('batch_predictions/*/*'):\n",
    "    try:\n",
    "        with open(entry, 'r') as f:\n",
    "            results = json.load(f)\n",
    "            class_index = np.argmax(np.array(results))\n",
    "            predicted_label = class_name_list[class_index]\n",
    "            predicted.append(class_index)\n",
    "            total += 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "        \n",
    "print(f'Found {total} prediction files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_many(in_list, which_value):\n",
    "    total_found = 0\n",
    "    for n in range(len(in_list)):\n",
    "        if in_list[n] == which_value:\n",
    "            total_found += 1\n",
    "    return total_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_totals_by_class = []\n",
    "for i in range(len(class_name_list)):\n",
    "    prediction_totals_by_class.append(how_many(predicted, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "x = np.arange(len(class_name_list))\n",
    "width = 0.7\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylabel('Prediction Counts')\n",
    "ax.set_title('Prediction Counts By Class')\n",
    "ax.bar(x, prediction_totals_by_class, width)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(class_name_list, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we take the highest probability class prediction for each image and compare that to the actual class of the image (represented by its class subfolder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "predicted = []\n",
    "actual = []\n",
    "\n",
    "for entry in glob.glob('batch_predictions/*/*'):\n",
    "    try:\n",
    "        actual_label = entry.split('/')[1]\n",
    "        actual_index = class_name_list.index(actual_label)\n",
    "        with open(entry, 'r') as f:\n",
    "            results = json.load(f)\n",
    "            class_index = np.argmax(np.array(results))\n",
    "            predicted_label = class_name_list[class_index]\n",
    "            predicted.append(class_index)\n",
    "            actual.append(actual_index)\n",
    "            is_correct = (predicted_label == actual_label) or False\n",
    "            if is_correct:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Out of {} total images, accurate predictions were returned for {}'.format(total, correct))\n",
    "accuracy = correct / total\n",
    "print('Accuracy is {:.1%}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.GnBu):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), \n",
    "                                  range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.gca().set_xticklabels(class_name_list)\n",
    "    plt.gca().set_yticklabels(class_name_list)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def create_and_plot_confusion_matrix(actual, predicted):\n",
    "    cnf_matrix = confusion_matrix(actual, np.asarray(predicted),labels=range(len(class_name_list)))\n",
    "    plot_confusion_matrix(cnf_matrix, classes=range(len(class_name_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_plot_confusion_matrix(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
