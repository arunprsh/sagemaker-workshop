# Amazon SageMaker - PyTorch Workshop using Image Classification

[Amazon SageMaker](https://aws.amazon.com/sagemaker/) provides every developer and data scientist the ability to build, train, and deploy machine learning models quickly. Amazon SageMaker is a fully-managed service that covers the entire machine learning workflow to label and prepare your data, choose an existing algorithm or build a new one, train the model, tune and optimize it, deploy the model, make predictions, and take action. Your models get to production faster with much less effort and lower cost.

This workshop provides a set of lab exercises that demonstrate how machine learning developers and data scientists can leverage SageMaker to train, build, optimize, and deploy PyTorch models. PyTorch and [Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/tf.html) can be used for a wide variety of machine learning use cases. This workshop uses an Image Classification problem throughout the series of labs. When creating your notebook instance for running these labs, be sure to pick an instance type that has sufficient memory (try `ml.c5.4xlarge`, not `ml.t3.medium`). Also, if you want to train with the full dataset, we recommend choosing an instance type with GPU support (e.g., `ml.p3.2xlarge`).

## Labs

### Using PyTorch natively in a SageMaker Jupyter notebook
This [introductory lab](./1_image_classification_birds.ipynb) introduces the bird species image classification problem and acts as a **baseline of using Amazon SageMaker with PyTorch**. The lab walks through preparing the data, and training an image classifier using transfer learning from a pretrained ResNet model. It also evaluates the model. All this is done in the context of a SageMaker hosted Jupyter notebook. For someone familiar with PyTorch, this is a straightforward first step of an end to end process directly from a SageMaker notebook.

### Leveraging SageMaker training and hosting with PyTorch
Building on the introductory lab, [this lab](./2_sm_image_classification_birds.ipynb) demonstrates the use of **SageMaker's PyTorch container**. It shows that migration of existing PyTorch models into the SageMaker platform is straightforward. SageMaker's managed training service is used to create training jobs on demand, reducing training cost by not paying for idle time. Similarly, the lab demonstrates deployment of PyTorch models behind a managed endpoint, providing an easy to use, scalable and cost effective approach to on demand predictions. Click [here](https://sagemaker.readthedocs.io/en/stable/using_pytorch.html) for details of using the container.

### Making batch predictions with SageMaker and PyTorch
[This lab](./3_batch_ic.ipynb) shows how to make **batch predictions with PyTorch on SageMaker**. Many customers have machine learning workloads that require a large number of predictions to be made reliably on a repeatable schedule. As compared to SageMaker's managed hosting service, inference compute capacity for batch predictions is spun up on demand and taken down upon completion of the batch. For large batch workloads, this represents significant cost savings over an always-on endpoint. Data scientists can stay focused on creating the best models, since [SageMaker batch](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) uses the same trained model easily across hosted endpoints and batch.

### Automatic model tuning of PyTorch models with SageMaker
[This lab](./4_auto_model_tuning.ipynb) demonstrates the power of **Amazon SageMaker's automatic model tuning capability**, also known as hyperparameter optimization (HPO). Instead of a labor intensive process of trial and error that could take days or weeks, [automatic model tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html) let's a data scientist ask SageMaker to find the optimal set of hyperparameters, typically in minutes or hours. The notebook shows how to provide a set of parameters to tune and ranges to consider, a metric to optimize on, some limits on the number of jobs to consider and the compute capacity to leverage. A SageMaker tuning job then efficiently explores options using a Bayesian optimization. SageMaker creates a set of models and highlights which one is optimal given your constraints. The resulting model is ready for deployment behind an endpoint or for batch predictions.